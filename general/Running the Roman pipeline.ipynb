{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Roman pipeline\n",
    "\n",
    "### Pipeline installation\n",
    "\n",
    "#### CRDS Setup\n",
    "\n",
    "Roman reference files are stored in the Calibration Reference Database System (CRDS). Access to it is enabled by the following environment variabes:\n",
    "\n",
    "```\n",
    "export CRDS_PATH=$HOME/crds_cache\n",
    "export CRDS_SERVER_URL=https://roman-crds-test.stsci.edu\n",
    "```\n",
    "\n",
    "**Note** that the above URL points to the TEST server which isn't publicly available but this is the way to set it up when a public server is online. The first time a reference file is accessed it is downloaded to the local cache. Subsequent uses of the file and offline access use the copy from the cache. Internally, at STScI the cache is available. For more information on CRDS consult the [CRDS User Guide](https://jwst-crds-test.stsci.edu/static/users_guide/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install a public release of the pipeline\n",
    "\n",
    "This section describes installation of a released version of the pipeline.\n",
    "\n",
    "Create a new conda environment, called \"roman-test\".\n",
    "(Caution Note: You need to be in zsh or bash. The new environment will inherit the current one. That means that if you are in the base conda environment and there are packages in it they will be available in the new environment unless you reinstall them there. This is generally bad because Python will also load packages from that base environment. A case, which is often a source for consfusion, is when ipython is not installed in the new environment but is available in the base one. Starting ipython owrks and loading a package may work but this package is imported from the base env and most often is a version different from what's desired.)\n",
    "\n",
    "```\n",
    "% conda create -n roman-test python=3.9\n",
    "```\n",
    "\n",
    "Activate the environment and install ipython and numpy\n",
    "\n",
    "```\n",
    "% conda activate roman-test\n",
    "% pip install jupyter\n",
    "% pip install numpy\n",
    "```\n",
    "\n",
    "Install the pipeline. The correct versions of the dependencies will be pulled in.\n",
    "\n",
    "```\n",
    "% pip install romancal\n",
    "```\n",
    "\n",
    "\n",
    "We are ready to run the pipeline.\n",
    "\n",
    "#### Install a development version of the pipeline\n",
    "\n",
    "This section describes installation of the `main` branch of the github repository.\n",
    "\n",
    "Create a new conda environment, called \"roman-dev\".\n",
    "\n",
    "```\n",
    "% conda create -n roman-dev python=3.9\n",
    "```\n",
    "\n",
    "Activate the environment and install ipython and numpy\n",
    "\n",
    "```\n",
    "% conda activate roman-dev\n",
    "% pip install jupyter\n",
    "% pip install numpy\n",
    "```\n",
    "\n",
    "Install the pipeline\n",
    "\n",
    "```\n",
    "pip install git+https://github.com/spacetelescope/romancal\n",
    "```\n",
    "### Code development\n",
    "\n",
    "There are several packages which are concurrently developed to support the Roman pipeline calibrations.\n",
    "Some are shared with the JWST pipeline.\n",
    "\n",
    "- rad: Roman schemas\n",
    "\n",
    "https://github.com/spacetelescope/rad\n",
    "\n",
    "- roman_datamodels: Datamodels for Roman data products\n",
    "\n",
    "https://github.com/spacetelescope/roman_datamodels\n",
    "\n",
    "- stpipe: Pipeline runner (shared with jwst)\n",
    "\n",
    "https://github.com/spacetelescope/stpipe\n",
    "\n",
    "- stcal: Core algorithms used in the pipeline (shared with jwst)\n",
    "\n",
    "https://github.com/spacetelescope/stcal\n",
    "\n",
    "- romancal: The actual pipeline code\n",
    "https://github.com/spacetelescope/romancal\n",
    "\n",
    "Installing romancal installs all its dependencies automatically.\n",
    "\n",
    "### Opening a data file as a data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.utils.data import download_file\n",
    "\n",
    "box_path = 'https://data.science.stsci.edu/redirect/Roman/Roman_Calibration_And_Datamodels/'\n",
    "level1_file = box_path + \"r0000101001001001001_01101_0001_WFI01_uncal.asdf\"\n",
    "\n",
    "level2_file = box_path + \"r0000101001001001001_01101_0001_WFI01_cal.asdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roman_datamodels import datamodels as rdm\n",
    "\n",
    "l1_file = download_file(level1_file)\n",
    "\n",
    "data_model = rdm.open(l1_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a special data model. Science data formatting creates a Level1 (`ScienceRawModel`) file, which is the input to the pipeline. \n",
    "\n",
    "The first step in the pipeline, `dqinit` needs to convert this to a `RampModel`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a step using reference files in CRDS\n",
    "\n",
    "#### On the command line\n",
    "\n",
    "```\n",
    "strun romancal.step.FlatFieldStep <input_file>\n",
    "```\n",
    "\n",
    "This runs the flat field step and saves the output in the current directory. The file suffix is `flatfieldstep`.\n",
    "\n",
    "The original `rate` suffix is preserved. *This is something that needs to be fixed!*\n",
    "\n",
    "#### In the Python interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from romancal.flatfield import FlatFieldStep\n",
    "\n",
    "l2_file = download_file(level2_file)\n",
    "result = FlatFieldStep.call(l2_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the output `result` is an ImageModel and can be saved to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.save('my_flat_fielded_image.asdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a step with local reference files\n",
    "\n",
    "#### On the command line\n",
    "\n",
    "```\n",
    "strun romancal.step.FlatFieldStep <input_file> --override_flat=myflat.asdf\n",
    "```\n",
    "\n",
    "\n",
    "#### In the Python interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from romancal.flatfield import FlatFieldStep\n",
    "\n",
    "result = FlatFieldStep.call(level2_file, override_flat=\"flat.asdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, to run the pipeline from the interpreter and pass custom reference files, one needs to use an argument name \n",
    "\n",
    "`override_<reference_file_type>=<file_name>`\n",
    "\n",
    "On the command line the syntax is \n",
    "\n",
    "`--override_<reference_file_type>=<file_name>`\n",
    "\n",
    "To find out what reference types a step uses and their names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from romancal.step import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"flat_field: \", FlatFieldStep.reference_file_types)\n",
    "print(\"dq_init: \", DQInitStep.reference_file_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of code development, a \"pipeline\" is a special \"step\", which runs other steps. This means the Exposure Level Pipeline can be run in the same way as an individual step.\n",
    "\n",
    "```\n",
    "strun romancal.pipeline.ExposurePipeline r0000101001001001001_01101_0001_WFI01_uncal.asdf\n",
    "```\n",
    "\n",
    "or using the pipeline alias, `roman_elp`,\n",
    "\n",
    "```\n",
    "strun roman_elp r0000101001001001001_01101_0001_WFI01_uncal.asdf\n",
    "```\n",
    "\n",
    "The syntax to run the pipeline in the Python interpreter is also the same as for an individual step.\n",
    "\n",
    "To list all available steps (note the list contains steps from all packages registered with stpipe):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stpipe list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
